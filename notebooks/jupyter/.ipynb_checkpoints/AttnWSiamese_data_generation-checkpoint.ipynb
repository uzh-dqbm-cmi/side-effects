{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ddi\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "from ddi.dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ddi.utilities import *\n",
    "from ddi.run_workflow import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata_dir = '../data/raw/'\n",
    "processed_dir = '../data/processed/'\n",
    "up_dir = '..'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "report_available_cuda_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gpu = torch.cuda.device_count()\n",
    "n_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DSdataset_name = 'DS3' # or DS2, DS3\n",
    "\n",
    "# For DS3:\n",
    "# interact_matfname_DS3 = 'NCRDInteractionMat'\n",
    "interact_matfname_DS3 = 'CRDInteractionMat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_configs = {'DS1':{'DSdataset_name':'DS1', \n",
    "                          'fname_suffix':\"_Jacarrd_sim.csv\",\n",
    "                          'similarity_types':['enzyme',\n",
    "                                              'indication',\n",
    "                                              'offsideeffect',\n",
    "                                              'pathway',\n",
    "                                              'sideeffect',\n",
    "                                              'target',\n",
    "                                              'transporter',\n",
    "                                              'chem'],\n",
    "                          'interact_matfname':'drug_drug_matrix',\n",
    "                          'exp_iden':'simtypeall',\n",
    "                          'kernel_option':'sqeuclidean',\n",
    "                          'data_fname':'data_v1',\n",
    "                          'ddi_interaction_labels_pth':os.path.join(up_dir, rawdata_dir, 'DS1', 'drug_drug_matrix.csv')}, \n",
    "                   'DS2':{'DSdataset_name':'DS2',\n",
    "                          'fname_suffix':'.csv',\n",
    "                          'similarity_types':['simMatrix'],\n",
    "                          'interact_matfname':'ddiMatrix',\n",
    "                          'exp_iden':'simtypeall',\n",
    "                          'kernel_option':'correlation',\n",
    "                          'ddi_interaction_labels_pth':os.path.join(up_dir, rawdata_dir, 'DS2', 'ddiMatrix.csv'),\n",
    "                          'data_fname':'data_v1'}, \n",
    "                   'DS3':{'DSdataset_name':'DS3',\n",
    "                          'fname_suffix':\"Mat.csv\",\n",
    "                          'similarity_types':['ATCSimilarity',\n",
    "                                              'chemicalSimilarity',\n",
    "                                              'distSimilarity',\n",
    "                                              'GOSimilarity',\n",
    "                                              'ligandSimilarity',\n",
    "                                              'seqSimilarity',\n",
    "                                              'SideEffectSimilarity'],\n",
    "                          'interact_matfname':['NCRDInteractionMat', 'CRDInteractionMat'],\n",
    "                          'exp_iden':['simtypeall_NCRDInteractionMat', 'simtypeall_CRDInteractionMat'],\n",
    "                          'kernel_option':'sqeuclidean',\n",
    "                          'ddi_interaction_labels_pth':[os.path.join(up_dir, rawdata_dir, 'DS3', 'NCRDInteractionMat.csv'), os.path.join(up_dir, rawdata_dir, 'DS3', 'CRDInteractionMat.csv')],\n",
    "                          'data_fname':'data_v1'}}\n",
    "\n",
    "dict_interact_matfname = {'NCRDInteractionMat': 0, 'CRDInteractionMat':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_config = dataset_configs[DSdataset_name]\n",
    "\n",
    "fname_suffix = ds_config[\"fname_suffix\"]\n",
    "similarity_types = ds_config[\"similarity_types\"]\n",
    "kernel_option = ds_config[\"kernel_option\"]\n",
    "data_fname = ds_config[\"data_fname\"]\n",
    "interact_matfname = ds_config[\"interact_matfname\"]\n",
    "exp_iden = ds_config[\"exp_iden\"]\n",
    "ddi_interaction_labels_pth = ds_config[\"ddi_interaction_labels_pth\"]\n",
    "\n",
    "if DSdataset_name == 'DS3':\n",
    "    int_interact_matfname = dict_interact_matfname[interact_matfname_DS3]\n",
    "    interact_matfname = interact_matfname[int_interact_matfname]\n",
    "    exp_iden = exp_iden[int_interact_matfname]\n",
    "    ddi_interaction_labels_pth = ddi_interaction_labels_pth[int_interact_matfname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = preprocess_labels(ddi_interaction_labels_pth, DSdataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_label_distrib(y), y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_drugs = get_num_drugs(ddi_interaction_labels_pth, DSdataset_name)\n",
    "num_drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_mat = get_interaction_mat(ddi_interaction_labels_pth, DSdataset_name)\n",
    "interaction_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid_ddipairs_map = construct_sampleid_ddipairs(interaction_mat)\n",
    "sid_ddipairs_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate datapartitions (i.e. train/val, test indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dpartitions = get_stratified_partitions(y, num_folds=10, valid_set_portion=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump data on disk\n",
    "targetdata_dir = create_directory(exp_iden, os.path.join(up_dir, processed_dir, DSdataset_name, data_fname))\n",
    "ReaderWriter.dump_data(dpartitions, os.path.join(targetdata_dir, 'data_partitions.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GIP computation for each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nan_idx(imat_mask):\n",
    "    r, c = np.where(np.isnan(imat_mask))\n",
    "    d = {}\n",
    "    for i in range(len(r)):\n",
    "        ridx= r[i]\n",
    "        cidx= c[i]\n",
    "        if ridx in d:\n",
    "            d[ridx].append(cidx)\n",
    "        else:\n",
    "            d[ridx] = [cidx]\n",
    "    return d\n",
    "\n",
    "def impute_nan(intmat, sim_mat, k=5, mask_value=np.nan):\n",
    "\n",
    "    mat = intmat.copy()\n",
    "    sim = sim_mat.copy()\n",
    "    np.fill_diagonal(mat,0)\n",
    "    np.fill_diagonal(sim,0)\n",
    "    (row,col) = mat.shape\n",
    "    \n",
    "    d = get_nan_idx(intmat)\n",
    "    nanw_m = np.ones(mat.shape)\n",
    "    for i, num_nan in enumerate(np.isnan(mat).sum(axis=1)):\n",
    "        if num_nan == 0:\n",
    "            continue\n",
    "        else:\n",
    "            curr_sim_vec = sim[i,:]\n",
    "            topk_indx = np.argsort(curr_sim_vec)[-k:]\n",
    "            coeff = curr_sim_vec[topk_indx]\n",
    "            norm = sum(coeff)\n",
    "\n",
    "            A = mat[topk_indx, :].copy()\n",
    "            A = A*coeff.reshape(-1,1)\n",
    "            vec_imat = np.nansum(A, axis=0)\n",
    "            \n",
    "            # update nan positions\n",
    "            mat[i,d[i]] = vec_imat[d[i]]\n",
    "            if norm > 0:\n",
    "                mat[i,d[i]] = mat[i,d[i]]/norm\n",
    "\n",
    "            # compute percent of nan in computation\n",
    "            nanw_vec = 1-np.isnan(A).sum(axis=0)/(A.shape[0])\n",
    "            nanw_m[i,d[i]] = nanw_vec[d[i]]\n",
    "\n",
    "    return mat, nanw_m\n",
    "\n",
    "def weight_inferred_mat(nanw_mat_lst, infer_mat_lst):\n",
    "    res_m = np.zeros(infer_mat_lst[0].shape)\n",
    "    nanw_m_accum = np.zeros(nanw_mat_lst[0].shape)\n",
    "    for i in range(len(nanw_mat_lst)):\n",
    "        nanw_m = nanw_mat_lst[i]\n",
    "        infer_m = infer_mat_lst[i]\n",
    "        res_m += nanw_m*infer_m\n",
    "        nanw_m_accum += nanw_m\n",
    "        \n",
    "    return res_m/nanw_m_accum\n",
    "\n",
    "def compute_gip_kernel(intmat, k_bandwidth, option='correlation'):\n",
    "    \"\"\"computes gaussian kernel from 2D matrix\n",
    "    \n",
    "       Approach based on van Laarhoven et al. doi:10.1093/bioinformatics/btr500\n",
    "    \n",
    "    \"\"\"\n",
    "    assert option in {'correlation', 'sqeuclidean'}\n",
    "    \n",
    "    mat = intmat.copy()\n",
    "    np.fill_diagonal(mat, 1) # to compensate for pair interactions\n",
    "    \n",
    "    r, c = mat.shape # 2D matrix\n",
    "    # computes pairwise correlation\n",
    "    dist_kernel = squareform(pdist(mat, metric=option))\n",
    "    print('nan',np.isnan(dist_kernel).sum())\n",
    "    if option == 'correlation':\n",
    "        avg_len = np.max(dist_kernel, axis=1, keepdims=True)\n",
    "        avg_len[np.where(avg_len <= 0)] = 1.\n",
    "        out = 1-dist_kernel/avg_len\n",
    "    else:\n",
    "        avg_len = (scpnorm(mat, axis=1, keepdims=True)**2) * 1/c\n",
    "        avg_len[np.where(avg_len <= 0)] = 1.\n",
    "        gamma = k_bandwidth/avg_len\n",
    "        out = np.exp(-gamma*dist_kernel)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using masking and inference with gip computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gip_perfold = {}\n",
    "for fold_id in dpartitions:\n",
    "    masked_intermat = interaction_mat.copy()\n",
    "    masked_intermat = masked_intermat.astype(np.float)\n",
    "    for dsettype in ('validation', 'test'):\n",
    "        # get validation/test ddi pair indices\n",
    "        sids = dpartitions[fold_id][dsettype]\n",
    "        a = [sid_ddipairs_map[sid][0] for sid in sids]\n",
    "        b = [sid_ddipairs_map[sid][1] for sid in sids]\n",
    "        # set to nan\n",
    "        masked_intermat[tuple([a,b])] = np.nan\n",
    "        masked_intermat[tuple([b,a])] = np.nan\n",
    "        \n",
    "    intermat_infer_lst = []\n",
    "    nanw_mat_lst = []\n",
    "    for similarity_type in similarity_types:\n",
    "        print('similarity_type', similarity_type)\n",
    "        siminput_feat_pth = os.path.join(up_dir, rawdata_dir, DSdataset_name, '{}{}'.format(similarity_type, fname_suffix))\n",
    "        sim_mat = get_similarity_matrix(siminput_feat_pth, DSdataset_name)\n",
    "        imat_infer, nanw_m = impute_nan(masked_intermat, sim_mat, k=15)\n",
    "        intermat_infer_lst.append(imat_infer)\n",
    "        nanw_mat_lst.append(nanw_m)\n",
    "        \n",
    "    infer_mat_fus = weight_inferred_mat(nanw_mat_lst, intermat_infer_lst)\n",
    "\n",
    "    print('norm(infer_mat-interaction_mat)', np.linalg.norm(infer_mat_fus - interaction_mat))\n",
    "\n",
    "    # compute GIP here\n",
    "    gip_kernel = compute_gip_kernel(infer_mat_fus, 1., kernel_option)\n",
    "    print('norm(gip_kernel-interaction_mat)',np.linalg.norm(gip_kernel - interaction_mat))\n",
    "    t = gip_kernel-interaction_mat\n",
    "    print(np.sum(np.abs(t) > 0.5)/(t.size - t.shape[0]))\n",
    "    gip_perfold[fold_id] = gip_kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute features from similarity matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check if similarity matrix is symmetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sim_types = len(similarity_types)\n",
    "for similarity_type in similarity_types:\n",
    "    siminput_feat_pth = os.path.join(up_dir, rawdata_dir, DSdataset_name, '{}{}'.format(similarity_type, fname_suffix))\n",
    "    sim_mat = get_similarity_matrix(siminput_feat_pth, DSdataset_name)   \n",
    "    print(np.allclose(sim_mat, np.transpose(sim_mat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sim_types = len(similarity_types)\n",
    "X_feats = []\n",
    "for similarity_type in similarity_types:\n",
    "    siminput_feat_pth = os.path.join(up_dir, rawdata_dir, DSdataset_name, '{}{}'.format(similarity_type, fname_suffix))\n",
    "    X_feat = preprocess_features(siminput_feat_pth, DSdataset_name, fill_diag=None)   \n",
    "    X_feats.append(X_feat)\n",
    "X_feat_cat = np.concatenate(X_feats, axis=1)\n",
    "print(\"X_feat_cat\", X_feat_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = create_setvector_features(X_feat_cat, 2*num_sim_types)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_a = X[:,list(range(0,2*num_sim_types,2))].copy()\n",
    "X_b = X[:,list(range(1,2*num_sim_types,2))].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ddi.utilities import format_bytes\n",
    "print(format_bytes(X_feat_cat.size * X_feat_cat.itemsize))\n",
    "print(format_bytes(y.size * y.itemsize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear unused objects\n",
    "del X_feats\n",
    "del X_feat_cat\n",
    "del X_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_cpu = get_device(to_gpu=False)\n",
    "device_gpu = get_device(True, index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtype is float32 since we will use sigmoid (binary outcome)\n",
    "y_tensor = torch.tensor(y, dtype = torch.int64, device = device_cpu) \n",
    "X_a = torch.tensor(X_a, dtype = torch.float32, device = device_cpu)\n",
    "X_b = torch.tensor(X_b, dtype = torch.float32, device = device_cpu)\n",
    "ddi_datatensor = DDIDataTensor(X_a, X_b, y_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetdata_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump data on disk\n",
    "ReaderWriter.dump_tensor(X_a, os.path.join(targetdata_dir, 'X_a.torch'))\n",
    "ReaderWriter.dump_tensor(X_b, os.path.join(targetdata_dir, 'X_b.torch'))\n",
    "ReaderWriter.dump_tensor(y_tensor, os.path.join(targetdata_dir, 'y_tensor.torch'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct GIP datatensor for each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gip_dtensor_perfold = {}\n",
    "for fold_id in gip_perfold:\n",
    "    print('fold_id:', fold_id)\n",
    "    gip_mat = gip_perfold[fold_id]\n",
    "    print('gip_mat:', gip_mat.shape)\n",
    "    gip_feat = get_features_from_simmatrix(gip_mat)\n",
    "    gip_all = create_setvector_features(gip_feat, 2)\n",
    "    print('gip_all:', gip_all.shape)\n",
    "    X_a_gip = gip_all[:,list(range(0,2*1,2))].copy()\n",
    "    X_b_gip = gip_all[:,list(range(1,2*1,2))].copy()\n",
    "    print('X_a_gip:', X_a_gip.shape)\n",
    "    X_a_gip = torch.tensor(X_a_gip, dtype = torch.float32, device = device_cpu)\n",
    "    X_b_gip = torch.tensor(X_b_gip, dtype = torch.float32, device = device_cpu)\n",
    "    gip_datatensor = GIPDataTensor(X_a_gip, X_b_gip)\n",
    "    gip_dtensor_perfold[fold_id] = gip_datatensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump data on disk\n",
    "ReaderWriter.dump_tensor(gip_dtensor_perfold, os.path.join(targetdata_dir, 'gip_dtensor_perfold.torch'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
