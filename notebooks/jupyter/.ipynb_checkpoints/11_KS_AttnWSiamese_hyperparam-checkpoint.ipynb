{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ddi\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "from ddi.dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ddi.utilities import *\n",
    "from ddi.run_workflow import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata_dir = '../data/raw/'\n",
    "processed_dir = '../data/processed/'\n",
    "up_dir = '..'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of GPUs available: 8\n",
      "cuda:0, name:GeForce GTX 1080 Ti\n",
      "total memory available: 10.91650390625 GB\n",
      "total memory allocated on device: 0.0 GB\n",
      "max memory allocated on device: 0.0 GB\n",
      "total memory cached on device: 0.0 GB\n",
      "max memory cached  on device: 0.0 GB\n",
      "\n",
      "cuda:1, name:GeForce GTX 1080 Ti\n",
      "total memory available: 10.91650390625 GB\n",
      "total memory allocated on device: 0.0 GB\n",
      "max memory allocated on device: 0.0 GB\n",
      "total memory cached on device: 0.0 GB\n",
      "max memory cached  on device: 0.0 GB\n",
      "\n",
      "cuda:2, name:GeForce GTX 1080 Ti\n",
      "total memory available: 10.91650390625 GB\n",
      "total memory allocated on device: 0.0 GB\n",
      "max memory allocated on device: 0.0 GB\n",
      "total memory cached on device: 0.0 GB\n",
      "max memory cached  on device: 0.0 GB\n",
      "\n",
      "cuda:3, name:GeForce GTX 1080 Ti\n",
      "total memory available: 10.91650390625 GB\n",
      "total memory allocated on device: 0.0 GB\n",
      "max memory allocated on device: 0.0 GB\n",
      "total memory cached on device: 0.0 GB\n",
      "max memory cached  on device: 0.0 GB\n",
      "\n",
      "cuda:4, name:GeForce GTX 1080 Ti\n",
      "total memory available: 10.91650390625 GB\n",
      "total memory allocated on device: 0.0 GB\n",
      "max memory allocated on device: 0.0 GB\n",
      "total memory cached on device: 0.0 GB\n",
      "max memory cached  on device: 0.0 GB\n",
      "\n",
      "cuda:5, name:GeForce GTX 1080 Ti\n",
      "total memory available: 10.91650390625 GB\n",
      "total memory allocated on device: 0.0 GB\n",
      "max memory allocated on device: 0.0 GB\n",
      "total memory cached on device: 0.0 GB\n",
      "max memory cached  on device: 0.0 GB\n",
      "\n",
      "cuda:6, name:GeForce GTX 1080 Ti\n",
      "total memory available: 10.91650390625 GB\n",
      "total memory allocated on device: 0.0 GB\n",
      "max memory allocated on device: 0.0 GB\n",
      "total memory cached on device: 0.0 GB\n",
      "max memory cached  on device: 0.0 GB\n",
      "\n",
      "cuda:7, name:GeForce GTX 1080 Ti\n",
      "total memory available: 10.91650390625 GB\n",
      "total memory allocated on device: 0.0 GB\n",
      "max memory allocated on device: 0.0 GB\n",
      "total memory cached on device: 0.0 GB\n",
      "max memory cached  on device: 0.0 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_available_cuda_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_gpu = torch.cuda.device_count()\n",
    "n_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DSdataset_name = 'DS3' # or DS2, DS3\n",
    "\n",
    "# For DS3:\n",
    "interact_matfname_DS3 = 'NCRDInteractionMat'\n",
    "# interact_matfname_DS3 = 'CRDInteractionMat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_configs = {'DS1':{'DSdataset_name':'DS1', \n",
    "                          'fname_suffix':\"_Jacarrd_sim.csv\",\n",
    "                          'similarity_types':['enzyme',\n",
    "                                              'indication',\n",
    "                                              'offsideeffect',\n",
    "                                              'pathway',\n",
    "                                              'sideeffect',\n",
    "                                              'target',\n",
    "                                              'transporter',\n",
    "                                              'chem'],\n",
    "                          'interact_matfname':'drug_drug_matrix',\n",
    "                          'exp_iden':'simtypeall',\n",
    "                          'kernel_option':'sqeuclidean',\n",
    "                          'data_fname':'data_v1',\n",
    "                          'ddi_interaction_labels_pth':os.path.join(up_dir, rawdata_dir, 'DS1', 'drug_drug_matrix.csv')}, \n",
    "                   'DS2':{'DSdataset_name':'DS2',\n",
    "                          'fname_suffix':'.csv',\n",
    "                          'similarity_types':['simMatrix'],\n",
    "                          'interact_matfname':'ddiMatrix',\n",
    "                          'exp_iden':'simtypeall',\n",
    "                          'kernel_option':'correlation',\n",
    "                          'ddi_interaction_labels_pth':os.path.join(up_dir, rawdata_dir, 'DS2', 'ddiMatrix.csv'),\n",
    "                          'data_fname':'data_v1'}, \n",
    "                   'DS3':{'DSdataset_name':'DS3',\n",
    "                          'fname_suffix':\"Mat.csv\",\n",
    "                          'similarity_types':['ATCSimilarity',\n",
    "                                              'chemicalSimilarity',\n",
    "                                              'distSimilarity',\n",
    "                                              'GOSimilarity',\n",
    "                                              'ligandSimilarity',\n",
    "                                              'seqSimilarity',\n",
    "                                              'SideEffectSimilarity'],\n",
    "                          'interact_matfname':['NCRDInteractionMat', 'CRDInteractionMat'],\n",
    "                          'exp_iden':['simtypeall_NCRDInteractionMat', 'simtypeall_CRDInteractionMat'],\n",
    "                          'kernel_option':'sqeuclidean',\n",
    "                          'ddi_interaction_labels_pth':[os.path.join(up_dir, rawdata_dir, 'DS3', 'NCRDInteractionMat.csv'), os.path.join(up_dir, rawdata_dir, 'DS3', 'CRDInteractionMat.csv')],\n",
    "                          'data_fname':'data_v1'}}\n",
    "\n",
    "dict_interact_matfname = {'NCRDInteractionMat': 0, 'CRDInteractionMat':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_config = dataset_configs[DSdataset_name]\n",
    "\n",
    "fname_suffix = ds_config[\"fname_suffix\"]\n",
    "similarity_types = ds_config[\"similarity_types\"]\n",
    "kernel_option = ds_config[\"kernel_option\"]\n",
    "data_fname = ds_config[\"data_fname\"]\n",
    "interact_matfname = ds_config[\"interact_matfname\"]\n",
    "exp_iden = ds_config[\"exp_iden\"]\n",
    "ddi_interaction_labels_pth = ds_config[\"ddi_interaction_labels_pth\"]\n",
    "\n",
    "if DSdataset_name == 'DS3':\n",
    "    int_interact_matfname = dict_interact_matfname[interact_matfname_DS3]\n",
    "    interact_matfname = interact_matfname[int_interact_matfname]\n",
    "    exp_iden = exp_iden[int_interact_matfname]\n",
    "    ddi_interaction_labels_pth = ddi_interaction_labels_pth[int_interact_matfname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_drugs = get_num_drugs(ddi_interaction_labels_pth, DSdataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_mat = get_interaction_mat(ddi_interaction_labels_pth, DSdataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid_ddipairs_map = construct_sampleid_ddipairs(interaction_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read relevant data stub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_current_dir ../../data/processed/DS3/data_v1\n"
     ]
    }
   ],
   "source": [
    "# read data from disk\n",
    "device_cpu = get_device(to_gpu=False)\n",
    "device_gpu = get_device(True, index=0)\n",
    "targetdata_dir = create_directory(exp_iden, os.path.join(up_dir, processed_dir, DSdataset_name, data_fname))\n",
    "dpartitions = ReaderWriter.read_data(os.path.join(targetdata_dir, 'data_partitions.pkl'))\n",
    "\n",
    "X_a = ReaderWriter.read_tensor(os.path.join(targetdata_dir, 'X_a.torch'), device_cpu)\n",
    "X_b = ReaderWriter.read_tensor(os.path.join(targetdata_dir, 'X_b.torch'), device_cpu)\n",
    "y_tensor = ReaderWriter.read_tensor(os.path.join(targetdata_dir, 'y_tensor.torch'), device_cpu)\n",
    "\n",
    "gip_dtensor_perfold =  ReaderWriter.read_tensor(os.path.join(targetdata_dir, 'gip_dtensor_perfold.torch'), device_cpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddi_datatensor = DDIDataTensor(X_a, X_b, y_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatensor_partitions = generate_partition_datatensor(ddi_datatensor, gip_dtensor_perfold, dpartitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold_num:0, dsettype:train\n",
      "ID(PartitionDataTensor) 47661235389272\n",
      "ID(DDIDataTensor) 47661235390896\n",
      "ID(GIPDataTensor) 47661235390784\n",
      "\n",
      "fold_num:0, dsettype:validation\n",
      "ID(PartitionDataTensor) 47661235391064\n",
      "ID(DDIDataTensor) 47661235390896\n",
      "ID(GIPDataTensor) 47661235390784\n",
      "\n",
      "fold_num:0, dsettype:test\n",
      "ID(PartitionDataTensor) 47661235389384\n",
      "ID(DDIDataTensor) 47661235390896\n",
      "ID(GIPDataTensor) 47661235390784\n",
      "\n",
      "fold_num:1, dsettype:train\n",
      "ID(PartitionDataTensor) 47661235390728\n",
      "ID(DDIDataTensor) 47661235390896\n",
      "ID(GIPDataTensor) 47661235391176\n",
      "\n",
      "fold_num:1, dsettype:validation\n",
      "ID(PartitionDataTensor) 47661235391400\n",
      "ID(DDIDataTensor) 47661235390896\n",
      "ID(GIPDataTensor) 47661235391176\n",
      "\n",
      "fold_num:1, dsettype:test\n",
      "ID(PartitionDataTensor) 47661235391456\n",
      "ID(DDIDataTensor) 47661235390896\n",
      "ID(GIPDataTensor) 47661235391176\n",
      "\n",
      "fold_num:2, dsettype:train\n",
      "ID(PartitionDataTensor) 47661235391512\n",
      "ID(DDIDataTensor) 47661235390896\n",
      "ID(GIPDataTensor) 47661235391232\n",
      "\n",
      "fold_num:2, dsettype:validation\n",
      "ID(PartitionDataTensor) 47661235391568\n",
      "ID(DDIDataTensor) 47661235390896\n",
      "ID(GIPDataTensor) 47661235391232\n",
      "\n",
      "fold_num:2, dsettype:test\n",
      "ID(PartitionDataTensor) 47661235391624\n",
      "ID(DDIDataTensor) 47661235390896\n",
      "ID(GIPDataTensor) 47661235391232\n",
      "\n",
      "fold_num:3, dsettype:train\n",
      "ID(PartitionDataTensor) 47661235391680\n",
      "ID(DDIDataTensor) 47661235390896\n",
      "ID(GIPDataTensor) 47661235391288\n",
      "\n",
      "fold_num:3, dsettype:validation\n",
      "ID(PartitionDataTensor) 47661235391736\n",
      "ID(DDIDataTensor) 47661235390896\n",
      "ID(GIPDataTensor) 47661235391288\n",
      "\n",
      "fold_num:3, dsettype:test\n",
      "ID(PartitionDataTensor) 47661235391792\n",
      "ID(DDIDataTensor) 47661235390896\n",
      "ID(GIPDataTensor) 47661235391288\n",
      "\n",
      "fold_num:4, dsettype:train\n",
      "ID(PartitionDataTensor) 47661235391848\n",
      "ID(DDIDataTensor) 47661235390896\n",
      "ID(GIPDataTensor) 47661235391344\n",
      "\n",
      "fold_num:4, dsettype:validation\n",
      "ID(PartitionDataTensor) 47661235391904\n",
      "ID(DDIDataTensor) 47661235390896\n",
      "ID(GIPDataTensor) 47661235391344\n",
      "\n",
      "fold_num:4, dsettype:test\n",
      "ID(PartitionDataTensor) 47661235391960\n",
      "ID(DDIDataTensor) 47661235390896\n",
      "ID(GIPDataTensor) 47661235391344\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# confirm that we separate PartitionDataTensor object and same reference to DDIDataTensor object!\n",
    "for fold_num in datatensor_partitions:\n",
    "    for dsettype in ('train', 'validation', 'test'):\n",
    "        print(f'fold_num:{fold_num}, dsettype:{dsettype}')\n",
    "        print('ID(PartitionDataTensor)', id(datatensor_partitions[fold_num][dsettype]))\n",
    "        print('ID(DDIDataTensor)', id(datatensor_partitions[fold_num][dsettype].ddi_datatensor))\n",
    "        print('ID(GIPDataTensor)', id(datatensor_partitions[fold_num][dsettype].gip_datatensor))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Evaluate workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ddi.run_workflow import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dditrf_config_map(input_dim, similarity_type, model_name, hyperparam_opt, loss_func='nllloss', margin=0.5, loss_w=0.5):\n",
    "    hyperparam_config = DDITrfHyperparamConfig(*hyperparam_opt)\n",
    "    fold_num = -1 \n",
    "    fdtype = torch.float32\n",
    "    mconfig, options = generate_models_config(hyperparam_config, similarity_type, model_name, input_dim, fold_num, fdtype, loss_func=loss_func, margin=margin, loss_w=loss_w)\n",
    "    return mconfig, options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "807"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_embed_dim = [128]\n",
    "num_attn_heads = [1,2]\n",
    "num_transformer_units = [1]\n",
    "p_dropout = [0.3, 0.45]\n",
    "nonlin_func = [nn.ReLU()]\n",
    "mlp_embed_factor = [2]\n",
    "pooling_mode = ['attn']\n",
    "dist_opt = ['cosine']\n",
    "l2_reg = [0,1e-8]\n",
    "batch_size = [400]\n",
    "num_epochs = [200]\n",
    "loss_w = [0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "hyperparam_space = list(itertools.product(*[input_embed_dim, num_attn_heads,  num_transformer_units, p_dropout,\n",
    "                                                nonlin_func, mlp_embed_factor,pooling_mode,dist_opt, l2_reg, batch_size,\n",
    "                                                num_epochs, loss_w]))\n",
    "print(len(hyperparam_space))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparam_opt = (input_embed_dim,num_attn_heads, num_transformer_units, p_dropout, \n",
    "                  nonlin_func, mlp_embed_factor, pooling_mode, dist_opt,\n",
    "                  l2_reg, batch_size, num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/processed/DS3/experiments/simtypeall_NCRDInteractionMat'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_dir = create_directory(exp_iden, os.path.join(processed_dir, DSdataset_name, 'experiments'))\n",
    "exp_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spawn_q_process(q_process):\n",
    "    print(\">>> spawning hyperparam search process\")\n",
    "    q_process.start()\n",
    "    \n",
    "def join_q_process(q_process):\n",
    "    q_process.join()\n",
    "    print(\"<<< joined hyperparam search process\")\n",
    "    \n",
    "def create_q_process(hyperparam_comb, gpu_num, datatensor_partition, exp_dir, num_drugs, queue, exp_iden):\n",
    "    fold_gpu_map = {0:gpu_num}\n",
    "    return mp.Process(target=ddi.run_workflow.train_test_hyperparam_conf, args=(hyperparam_comb, \n",
    "                                                                                gpu_num, \n",
    "                                                                                datatensor_partition, \n",
    "                                                                                fold_gpu_map, \n",
    "                                                                                exp_dir, \n",
    "                                                                                num_drugs, \n",
    "                                                                                queue,\n",
    "                                                                                exp_iden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> spawning hyperparam search process\n",
      ">>> spawning hyperparam search process\n",
      ">>> spawning hyperparam search process\n",
      ">>> spawning hyperparam search process\n",
      ">>> spawning hyperparam search process\n",
      ">>> spawning hyperparam search process\n",
      ">>> spawning hyperparam search process\n",
      ">>> spawning hyperparam search process\n",
      "<<< joined hyperparam search process\n",
      "released_gpu_num: 3\n",
      "<<< joined hyperparam search process\n",
      "released_gpu_num: 2\n",
      "<<< joined hyperparam search process\n",
      "released_gpu_num: 0\n",
      "<<< joined hyperparam search process\n",
      "released_gpu_num: 1\n",
      "<<< joined hyperparam search process\n",
      "released_gpu_num: 5\n",
      "<<< joined hyperparam search process\n",
      "released_gpu_num: 7\n",
      "<<< joined hyperparam search process\n",
      "released_gpu_num: 4\n",
      "<<< joined hyperparam search process\n",
      "released_gpu_num: 6\n"
     ]
    }
   ],
   "source": [
    "import torch.multiprocessing as mp\n",
    "mp.set_start_method(\"spawn\", force=True)\n",
    "\n",
    "queue = mp.Queue()\n",
    "q_processes = []\n",
    "\n",
    "for q_i in range(min(n_gpu, len(hyperparam_space))):\n",
    "    q_process = create_q_process(hyperparam_comb=hyperparam_space[q_i], \n",
    "                                 gpu_num=q_i, \n",
    "                                 datatensor_partition={0:datatensor_partitions[0]}, \n",
    "                                 exp_dir=exp_dir, \n",
    "                                 num_drugs=num_drugs, \n",
    "                                 queue=queue,\n",
    "                                 exp_iden=exp_iden)\n",
    "    q_processes.append(q_process)\n",
    "    spawn_q_process(q_process)\n",
    "\n",
    "spawned_processes = n_gpu\n",
    "    \n",
    "for q_i in range(len(hyperparam_space)):\n",
    "    join_q_process(q_processes[q_i])\n",
    "    released_gpu_num = queue.get()\n",
    "    print(\"released_gpu_num:\", released_gpu_num)\n",
    "    if(spawned_processes < len(hyperparam_space)):\n",
    "        q_process = create_q_process(hyperparam_comb=hyperparam_space[spawned_processes], \n",
    "                             gpu_num=released_gpu_num, \n",
    "                             datatensor_partition={0:datatensor_partitions[0]}, \n",
    "                             exp_dir=exp_dir, \n",
    "                             num_drugs=num_drugs, \n",
    "                             queue=queue,\n",
    "                             exp_iden=exp_iden)\n",
    "        q_processes.append(q_process)\n",
    "        spawn_q_process(q_process)\n",
    "        spawned_processes = spawned_processes + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
