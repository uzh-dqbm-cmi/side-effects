{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# Provide access to modules in repo.\n",
    "sys.path.insert(0, os.path.abspath('../../'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import ddi\n",
    "from ddi.dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ddi.utilities import *\n",
    "from ddi.run_workflow import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata_dir = '../data/raw/'\n",
    "processed_dir = '../data/processed/'\n",
    "up_dir = '..'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_available_cuda_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gpu = torch.cuda.device_count()\n",
    "n_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DSdataset_name = 'DS1' # or DS2, DS3\n",
    "\n",
    "# For DS3:\n",
    "if DSdataset_name == 'DS3':\n",
    "#     interact_matfname_DS3 = 'NCRDInteractionMat'\n",
    "    interact_matfname_DS3 = 'CRDInteractionMat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_configs = {'DS1':{'DSdataset_name':'DS1', \n",
    "                          'fname_suffix':\"_Jacarrd_sim.csv\",\n",
    "                          'similarity_types':['enzyme',\n",
    "                                              'indication',\n",
    "                                              'offsideeffect',\n",
    "                                              'pathway',\n",
    "                                              'sideeffect',\n",
    "                                              'target',\n",
    "                                              'transporter',\n",
    "                                              'chem'],\n",
    "                          'interact_matfname':'drug_drug_matrix',\n",
    "                          'exp_iden':'simtypeall',\n",
    "                          'kernel_option':'sqeuclidean',\n",
    "                          'data_fname':'data_v1',\n",
    "                          'ddi_interaction_labels_pth':os.path.join(up_dir, rawdata_dir, 'DS1', 'drug_drug_matrix.csv')}, \n",
    "                   'DS2':{'DSdataset_name':'DS2',\n",
    "                          'fname_suffix':'.csv',\n",
    "                          'similarity_types':['simMatrix'],\n",
    "                          'interact_matfname':'ddiMatrix',\n",
    "                          'exp_iden':'simtypeall',\n",
    "                          'kernel_option':'correlation',\n",
    "                          'ddi_interaction_labels_pth':os.path.join(up_dir, rawdata_dir, 'DS2', 'ddiMatrix.csv'),\n",
    "                          'data_fname':'data_v1'}, \n",
    "                   'DS3':{'DSdataset_name':'DS3',\n",
    "                          'fname_suffix':\"Mat.csv\",\n",
    "                          'similarity_types':['ATCSimilarity',\n",
    "                                              'chemicalSimilarity',\n",
    "                                              'distSimilarity',\n",
    "                                              'GOSimilarity',\n",
    "                                              'ligandSimilarity',\n",
    "                                              'seqSimilarity',\n",
    "                                              'SideEffectSimilarity'],\n",
    "                          'interact_matfname':['NCRDInteractionMat', 'CRDInteractionMat'],\n",
    "                          'exp_iden':['simtypeall_NCRDInteractionMat', 'simtypeall_CRDInteractionMat'],\n",
    "                          'kernel_option':'sqeuclidean',\n",
    "                          'ddi_interaction_labels_pth':[os.path.join(up_dir, rawdata_dir, 'DS3', 'NCRDInteractionMat.csv'), os.path.join(up_dir, rawdata_dir, 'DS3', 'CRDInteractionMat.csv')],\n",
    "                          'data_fname':'data_v1'}}\n",
    "\n",
    "dict_interact_matfname = {'NCRDInteractionMat': 0, 'CRDInteractionMat':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_config = dataset_configs[DSdataset_name]\n",
    "\n",
    "fname_suffix = ds_config[\"fname_suffix\"]\n",
    "similarity_types = ds_config[\"similarity_types\"]\n",
    "kernel_option = ds_config[\"kernel_option\"]\n",
    "data_fname = ds_config[\"data_fname\"]\n",
    "interact_matfname = ds_config[\"interact_matfname\"]\n",
    "exp_iden = ds_config[\"exp_iden\"]\n",
    "ddi_interaction_labels_pth = ds_config[\"ddi_interaction_labels_pth\"]\n",
    "\n",
    "if DSdataset_name == 'DS3':\n",
    "    int_interact_matfname = dict_interact_matfname[interact_matfname_DS3]\n",
    "    interact_matfname = interact_matfname[int_interact_matfname]\n",
    "    exp_iden = exp_iden[int_interact_matfname]\n",
    "    ddi_interaction_labels_pth = ddi_interaction_labels_pth[int_interact_matfname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_drugs = get_num_drugs(ddi_interaction_labels_pth, DSdataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_mat = get_interaction_mat(ddi_interaction_labels_pth, DSdataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid_ddipairs_map = construct_sampleid_ddipairs(interaction_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read relevant data stub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from disk\n",
    "device_cpu = get_device(to_gpu=False)\n",
    "device_gpu = get_device(True, index=0)\n",
    "targetdata_dir = create_directory(exp_iden, os.path.join(up_dir, processed_dir, DSdataset_name, data_fname))\n",
    "dpartitions = ReaderWriter.read_data(os.path.join(targetdata_dir, 'data_partitions.pkl'))\n",
    "\n",
    "X_a = ReaderWriter.read_tensor(os.path.join(targetdata_dir, 'X_a.torch'), device_cpu)\n",
    "X_b = ReaderWriter.read_tensor(os.path.join(targetdata_dir, 'X_b.torch'), device_cpu)\n",
    "y_tensor = ReaderWriter.read_tensor(os.path.join(targetdata_dir, 'y_tensor.torch'), device_cpu)\n",
    "\n",
    "gip_dtensor_perfold =  ReaderWriter.read_tensor(os.path.join(targetdata_dir, 'gip_dtensor_perfold.torch'), device_cpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genearte data tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddi_datatensor = DDIDataTensor(X_a, X_b, y_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatensor_partitions = generate_partition_datatensor(ddi_datatensor, gip_dtensor_perfold, dpartitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# confirm that we separate PartitionDataTensor object and same reference to DDIDataTensor object!\n",
    "for fold_num in datatensor_partitions:\n",
    "    for dsettype in ('train', 'validation', 'test'):\n",
    "        print(f'fold_num:{fold_num}, dsettype:{dsettype}')\n",
    "        print('ID(PartitionDataTensor)', id(datatensor_partitions[fold_num][dsettype]))\n",
    "        print('ID(DDIDataTensor)', id(datatensor_partitions[fold_num][dsettype].ddi_datatensor))\n",
    "        print('ID(GIPDataTensor)', id(datatensor_partitions[fold_num][dsettype].gip_datatensor))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ddi.run_workflow import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dditrf_config_map(input_dim, similarity_type, model_name, hyperparam_opt, loss_func='nllloss', margin=0.5, loss_w=0.5):\n",
    "    hyperparam_config = DDITrfHyperparamConfig(*hyperparam_opt)\n",
    "    fold_num = -1 \n",
    "    fdtype = torch.float32\n",
    "    mconfig, options = generate_models_config(hyperparam_config, similarity_type, model_name, input_dim, fold_num, fdtype, loss_func=loss_func, margin=margin, loss_w=loss_w)\n",
    "    return mconfig, options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of hyperparameter options to consider\n",
    "input_embed_dim = [128]\n",
    "num_attn_heads = [1,2]\n",
    "num_transformer_units = [1]\n",
    "p_dropout = [0.3, 0.45]\n",
    "nonlin_func = [nn.ReLU()]\n",
    "mlp_embed_factor = [2]\n",
    "pooling_mode = ['attn']\n",
    "dist_opt = ['cosine']\n",
    "l2_reg = [0,1e-6, 1e-8]\n",
    "batch_size = [400,1000]\n",
    "num_epochs = [100, 200]\n",
    "loss_w = [0.5, 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparam_opt = (input_embed_dim,num_attn_heads, num_transformer_units, p_dropout, \n",
    "                  nonlin_func, mlp_embed_factor, pooling_mode, dist_opt,\n",
    "                  l2_reg, batch_size, num_epochs, loss_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparam_space = list(itertools.product(*hyperparam_opt))\n",
    "print(len(hyperparam_space))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp_dir = create_directory(exp_iden, os.path.join(processed_dir, DSdataset_name, 'experiments'))\n",
    "exp_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spawn_q_process(q_process):\n",
    "    print(\">>> spawning hyperparam search process\")\n",
    "    q_process.start()\n",
    "    \n",
    "def join_q_process(q_process):\n",
    "    q_process.join()\n",
    "    print(\"<<< joined hyperparam search process\")\n",
    "    \n",
    "def create_q_process(hyperparam_comb, gpu_num, datatensor_partition, fold_gpu_map, exp_dir, num_drugs, queue, exp_iden):\n",
    "    return mp.Process(target=ddi.run_workflow.train_test_hyperparam_conf, args=(hyperparam_comb, \n",
    "                                                                                gpu_num, \n",
    "                                                                                datatensor_partition, \n",
    "                                                                                fold_gpu_map, \n",
    "                                                                                exp_dir, \n",
    "                                                                                num_drugs, \n",
    "                                                                                queue,\n",
    "                                                                                exp_iden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.multiprocessing as mp\n",
    "mp.set_start_method(\"spawn\", force=True)\n",
    "\n",
    "queue = mp.Queue()\n",
    "q_processes = []\n",
    "num_hyper_options = len(hyperparam_space)\n",
    "spawned_processes = min(n_gpu, num_hyper_options)\n",
    "chosen_fold = 0\n",
    "\n",
    "for q_i in range(spawned_processes):\n",
    "    \n",
    "    fold_gpu_map = {chosen_fold:q_i}\n",
    "    q_process = create_q_process(hyperparam_comb=hyperparam_space[q_i], \n",
    "                                 gpu_num=q_i, \n",
    "                                 datatensor_partition={chosen_fold:datatensor_partitions[chosen_fold]},\n",
    "                                 fold_gpu_map=fold_gpu_map,\n",
    "                                 exp_dir=exp_dir, \n",
    "                                 num_drugs=num_drugs, \n",
    "                                 queue=queue,\n",
    "                                 exp_iden=exp_iden)\n",
    "    q_processes.append(q_process)\n",
    "    spawn_q_process(q_process)\n",
    "\n",
    "spawned_processes = n_gpu\n",
    "    \n",
    "for q_i in range(num_hyper_options):\n",
    "    join_q_process(q_processes[q_i])\n",
    "    released_gpu_num = queue.get()\n",
    "    print(\"released_gpu_num:\", released_gpu_num)\n",
    "    if(spawned_processes < num_hyper_options):\n",
    "        fold_gpu_map = {chosen_fold:released_gpu_num}\n",
    "        q_process = create_q_process(hyperparam_comb=hyperparam_space[spawned_processes],\n",
    "                                     gpu_num=released_gpu_num,\n",
    "                                     datatensor_partition={chosen_fold:datatensor_partitions[chosen_fold]},\n",
    "                                     fold_gpu_map=fold_gpu_map,\n",
    "                                     exp_dir=exp_dir, \n",
    "                                     num_drugs=num_drugs, \n",
    "                                     queue=queue,\n",
    "                                     exp_iden=exp_iden)\n",
    "        q_processes.append(q_process)\n",
    "        spawn_q_process(q_process)\n",
    "        spawned_processes = spawned_processes + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
